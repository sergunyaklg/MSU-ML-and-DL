{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 7.1. F1-measure\n",
        "\n",
        "На [лекции](https://colab.research.google.com/drive/12xpYdqi1S4y68FYHym2rZ3wzHSm8cSLm?usp=sharing) мы подробно обсудили, что доля правильных ответов - не самая лучшая метрика оценки качества классификации. Довольно часто доля правильных ответов даёт смещенную оценку качества и способна ввести в заблуждение. По этой причине мы пользуемся метриками качества, которые называются *точностью* и *полнотой*, а также их комбинацией - *F1-мерой*. Ваша задача - реализовать функции `precision`, `recall` и `f1`. На вход всех этих функий подаются два вектора: `y_true`: вектор правильных ответов и `y_pred`: вектор предсказаний.\n",
        "\n",
        "В рамках выполнения этого задания можно использовать только модуль `numpy`."
      ],
      "metadata": {
        "id": "qnxzhw-2a0ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    assert len(y_true) == len(y_pred), \"Input vectors should have the same length\"\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    if TP + FP == 0:\n",
        "        return 0\n",
        "    return TP / (TP + FP)\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    assert len(y_true) == len(y_pred), \"Input vectors should have the same length\"\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    if TP + FN == 0:\n",
        "        return 0\n",
        "    return TP / (TP + FN)\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    assert len(y_true) == len(y_pred), \"Input vectors should have the same length\"\n",
        "    prec = precision(y_true, y_pred)\n",
        "    rec = recall(y_true, y_pred)\n",
        "    if prec + rec == 0:\n",
        "        return 0\n",
        "    return 2 * (prec * rec) / (prec + rec)"
      ],
      "metadata": {
        "id": "DpNEqX0_cL9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Примечания\n",
        "\n",
        "1. Проверить себя Вы можете, сравнив свои ответы с функциями `sklearn.metrics.precision_score`, `sklearn.metrics.recall_score` и `sklearn.metrics.f1_score`.\n",
        "\n",
        "2. В реализуемых методах запрещается использовать вывод любой информации на экран (в частности, недопустимо использование print()).\n",
        "\n",
        "3. Для улучшения качества кода мы не рекомендуем заново реализовывать вычисление precision и recall внутри метода f1. Достаточно просто внутри метода f1 вызвать уже реализованные вами ранее методы self.precision() и self.recall().\n",
        "\n",
        "4. Мы считаем, что исследуемый класс возвращает метки 0 или 1 (случай возвращения меток -1 и 1 можно не рассматривать, но для более корректного решения рекомендуем также учесть и эту ситуацию).\n",
        "\n",
        "5. Реализуемые функции не должны ничего выводить на экран - они должны возвращать значения соответствующих метрик."
      ],
      "metadata": {
        "id": "dYFHfq7iMXIu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ISa-XPO74jdS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}